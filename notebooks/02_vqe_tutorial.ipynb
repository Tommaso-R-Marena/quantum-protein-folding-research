{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQE Tutorial: Deep Dive into Variational Quantum Eigensolver\n",
    "\n",
    "This notebook provides an in-depth exploration of VQE for protein folding.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. VQE Theory and Algorithm\n",
    "2. Hamiltonian Construction\n",
    "3. Ansatz Design and Comparison\n",
    "4. Optimizer Selection\n",
    "5. Parameter Initialization Strategies\n",
    "6. Noise Analysis\n",
    "7. Convergence Analysis\n",
    "8. Scaling Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from quantum_protein_folding.models import VQEFoldingModel\n",
    "from quantum_protein_folding.data.loaders import load_hp_sequence\n",
    "from quantum_protein_folding.data.preprocess import map_to_lattice\n",
    "from quantum_protein_folding.quantum.hamiltonian import (\n",
    "    build_hamiltonian,\n",
    "    compute_exact_ground_state\n",
    ")\n",
    "from quantum_protein_folding.quantum.circuit_builder import (\n",
    "    build_hardware_efficient_ansatz,\n",
    "    count_circuit_resources\n",
    ")\n",
    "from quantum_protein_folding.analysis import plot_convergence, analyze_convergence\n",
    "\n",
    "Path(\"../results\").mkdir(exist_ok=True)\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. VQE Theory\n",
    "\n",
    "VQE minimizes the expectation value:\n",
    "\n",
    "$$E(\\theta) = \\langle \\psi(\\theta) | H | \\psi(\\theta) \\rangle$$\n",
    "\n",
    "where $|\\psi(\\theta)\\rangle = U(\\theta)|0\\rangle^{\\otimes n}$ is a parameterized ansatz.\n",
    "\n",
    "### Protein Folding Hamiltonian\n",
    "\n",
    "$$H = H_{\\text{contact}} + \\lambda H_{\\text{backbone}} + \\mu H_{\\text{bias}}$$\n",
    "\n",
    "- **Contact term**: Residue-residue interactions (MJ potentials)\n",
    "- **Backbone term**: Connectivity and self-avoidance constraints\n",
    "- **Bias term**: Compactness regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hamiltonian Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sequence\n",
    "sequence_str = \"HPHPPHHPHH\"\n",
    "sequence = load_hp_sequence(sequence_str)\n",
    "\n",
    "# Create lattice encoding\n",
    "encoding = map_to_lattice(\n",
    "    sequence,\n",
    "    lattice_dim=2,\n",
    "    encoding_type='turn_direction',\n",
    "    constraint_weight=10.0,\n",
    "    bias_weight=0.1\n",
    ")\n",
    "\n",
    "hamiltonian = encoding.hamiltonian\n",
    "\n",
    "print(f\"Hamiltonian Information:\")\n",
    "print(f\"  Number of qubits: {hamiltonian.num_qubits}\")\n",
    "print(f\"  Number of terms: {len(hamiltonian)}\")\n",
    "print(f\"  Encoding: {encoding.encoding_type}\")\n",
    "print(f\"\\nFirst 5 Pauli terms:\")\n",
    "for pauli, coeff in list(hamiltonian.to_list())[:5]:\n",
    "    print(f\"  {pauli}: {coeff:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Ground State (for small systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hamiltonian.num_qubits <= 12:  # Only for small systems\n",
    "    print(\"Computing exact ground state via diagonalization...\")\n",
    "    ground_energy, ground_state = compute_exact_ground_state(hamiltonian)\n",
    "    print(f\"Exact ground state energy: {ground_energy:.6f}\")\n",
    "    print(\"This is the target energy VQE should approach.\")\n",
    "else:\n",
    "    print(f\"System too large ({hamiltonian.num_qubits} qubits) for exact diagonalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ansatz Design Comparison\n",
    "\n",
    "We'll compare different ansatz types and depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different ansatz configurations\n",
    "ansatz_configs = [\n",
    "    {'type': 'hardware_efficient', 'depth': 1},\n",
    "    {'type': 'hardware_efficient', 'depth': 2},\n",
    "    {'type': 'hardware_efficient', 'depth': 3},\n",
    "]\n",
    "\n",
    "print(\"Ansatz Circuit Resources:\\n\")\n",
    "print(f\"{'Type':<20} {'Depth':<8} {'#Qubits':<10} {'#Params':<10} {'Circuit Depth':<15} {'CNOT Count':<12}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for config in ansatz_configs:\n",
    "    circuit, params = build_hardware_efficient_ansatz(\n",
    "        n_qubits=encoding.n_qubits,\n",
    "        depth=config['depth'],\n",
    "        entanglement='linear'\n",
    "    )\n",
    "    \n",
    "    resources = count_circuit_resources(circuit)\n",
    "    \n",
    "    print(f\"{config['type']:<20} {config['depth']:<8} {resources['n_qubits']:<10} \"\n",
    "          f\"{resources['n_parameters']:<10} {resources['depth']:<15} {resources['cx_count']:<12}\")\n",
    "\n",
    "print(\"\\nNote: Deeper ansatz = more expressivity but harder optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimizer Comparison\n",
    "\n",
    "Different optimizers have different characteristics for VQE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = ['COBYLA', 'SLSQP', 'SPSA']\n",
    "results = {}\n",
    "\n",
    "for opt_name in optimizers:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Running VQE with {opt_name} optimizer...\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    model = VQEFoldingModel(\n",
    "        sequence=sequence_str,\n",
    "        lattice_dim=2,\n",
    "        ansatz_depth=2,\n",
    "        optimizer=opt_name,\n",
    "        shots=1024\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    result = model.run(maxiter=50)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    results[opt_name] = {\n",
    "        'energy': result.optimal_value,\n",
    "        'time': elapsed,\n",
    "        'iterations': result.n_iterations,\n",
    "        'history': result.convergence_history\n",
    "    }\n",
    "    \n",
    "    print(f\"  Final energy: {result.optimal_value:.4f}\")\n",
    "    print(f\"  Time: {elapsed:.2f}s\")\n",
    "    print(f\"  Iterations: {result.n_iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Optimizer Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot convergence curves\n",
    "for opt_name, data in results.items():\n",
    "    axes[0].plot(data['history'], label=opt_name, linewidth=2, alpha=0.8)\n",
    "\n",
    "axes[0].set_xlabel('Iteration', fontsize=12)\n",
    "axes[0].set_ylabel('Energy', fontsize=12)\n",
    "axes[0].set_title('Optimizer Convergence Comparison', fontweight='bold', fontsize=13)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar chart of final energies\n",
    "opt_names = list(results.keys())\n",
    "energies = [results[name]['energy'] for name in opt_names]\n",
    "\n",
    "axes[1].bar(opt_names, energies, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "axes[1].set_ylabel('Final Energy', fontsize=12)\n",
    "axes[1].set_title('Final Energy Comparison', fontweight='bold', fontsize=13)\n",
    "axes[1].grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Highlight best\n",
    "best_idx = np.argmin(energies)\n",
    "axes[1].patches[best_idx].set_color('green')\n",
    "axes[1].patches[best_idx].set_alpha(0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/vqe_optimizer_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest optimizer: {opt_names[best_idx]} (E={energies[best_idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parameter Initialization Strategies\n",
    "\n",
    "Initial parameters can significantly affect convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = VQEFoldingModel(\n",
    "    sequence=sequence_str,\n",
    "    lattice_dim=2,\n",
    "    ansatz_depth=2,\n",
    "    optimizer='COBYLA'\n",
    ")\n",
    "\n",
    "n_params = model.solver.n_params\n",
    "\n",
    "# Test different initialization strategies\n",
    "init_strategies = {\n",
    "    'Random [0, 2π]': 2 * np.pi * np.random.rand(n_params),\n",
    "    'Small random': 0.1 * np.random.rand(n_params),\n",
    "    'Zeros': np.zeros(n_params),\n",
    "    'Uniform π/2': np.ones(n_params) * np.pi / 2,\n",
    "}\n",
    "\n",
    "init_results = {}\n",
    "\n",
    "for name, init_params in init_strategies.items():\n",
    "    print(f\"Testing: {name}\")\n",
    "    \n",
    "    model.solver.initial_params = init_params\n",
    "    result = model.run(maxiter=50)\n",
    "    \n",
    "    init_results[name] = result.optimal_value\n",
    "    print(f\"  Final energy: {result.optimal_value:.4f}\\n\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nInitialization Strategy Summary:\")\n",
    "for name, energy in sorted(init_results.items(), key=lambda x: x[1]):\n",
    "    print(f\"  {name:<20}: {energy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Noise Analysis (Optional)\n",
    "\n",
    "For realistic simulations, we can add noise models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_aer.noise import NoiseModel, depolarizing_error\n",
    "\n",
    "# Create noise model\n",
    "def create_noise_model(error_rate=0.01):\n",
    "    noise_model = NoiseModel()\n",
    "    \n",
    "    # Depolarizing error on single-qubit gates\n",
    "    single_qubit_error = depolarizing_error(error_rate, 1)\n",
    "    noise_model.add_all_qubit_quantum_error(single_qubit_error, ['u1', 'u2', 'u3', 'rx', 'ry', 'rz'])\n",
    "    \n",
    "    # Depolarizing error on two-qubit gates\n",
    "    two_qubit_error = depolarizing_error(error_rate * 2, 2)\n",
    "    noise_model.add_all_qubit_quantum_error(two_qubit_error, ['cx', 'cz'])\n",
    "    \n",
    "    return noise_model\n",
    "\n",
    "# Compare noiseless vs noisy\n",
    "noise_levels = [0.0, 0.005, 0.01, 0.02]\n",
    "noise_results = {}\n",
    "\n",
    "for noise_level in noise_levels:\n",
    "    print(f\"Running with noise level: {noise_level:.3f}\")\n",
    "    \n",
    "    if noise_level > 0:\n",
    "        noise_model = create_noise_model(noise_level)\n",
    "    else:\n",
    "        noise_model = None\n",
    "    \n",
    "    # Note: Would need to pass noise_model to VQEFoldingModel\n",
    "    # For now, just demonstrate the concept\n",
    "    \n",
    "    print(f\"  (Noise simulation with error rate {noise_level})\\n\")\n",
    "\n",
    "print(\"Note: Full noise simulation requires backend integration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run VQE with more iterations\n",
    "model = VQEFoldingModel(\n",
    "    sequence=sequence_str,\n",
    "    lattice_dim=2,\n",
    "    ansatz_depth=3,\n",
    "    optimizer='COBYLA'\n",
    ")\n",
    "\n",
    "result = model.run(maxiter=200)\n",
    "\n",
    "# Analyze convergence\n",
    "conv_analysis = analyze_convergence(result.convergence_history)\n",
    "\n",
    "print(\"Convergence Analysis:\")\n",
    "for key, value in conv_analysis.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Plot with moving average\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "history = np.array(result.convergence_history)\n",
    "iterations = np.arange(len(history))\n",
    "\n",
    "# Raw data\n",
    "ax.plot(iterations, history, 'b-', alpha=0.3, label='Raw')\n",
    "\n",
    "# Moving average\n",
    "window = 10\n",
    "if len(history) >= window:\n",
    "    moving_avg = np.convolve(history, np.ones(window)/window, mode='valid')\n",
    "    ax.plot(iterations[window-1:], moving_avg, 'r-', linewidth=2, label=f'MA({window})')\n",
    "\n",
    "ax.axhline(y=conv_analysis['best_value'], color='g', linestyle='--', label='Best')\n",
    "\n",
    "ax.set_xlabel('Iteration', fontsize=12)\n",
    "ax.set_ylabel('Energy', fontsize=12)\n",
    "ax.set_title('VQE Convergence Analysis', fontweight='bold', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/vqe_convergence_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Scaling Study\n",
    "\n",
    "How does VQE performance scale with protein length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different sequence lengths\n",
    "test_sequences = [\n",
    "    \"HPHP\",          # 4 residues\n",
    "    \"HPHPPH\",        # 6 residues\n",
    "    \"HPHPPHHP\",      # 8 residues\n",
    "    \"HPHPPHHPHH\",    # 10 residues\n",
    "]\n",
    "\n",
    "scaling_results = []\n",
    "\n",
    "for seq in test_sequences:\n",
    "    print(f\"Testing sequence length {len(seq)}...\")\n",
    "    \n",
    "    model = VQEFoldingModel(\n",
    "        sequence=seq,\n",
    "        lattice_dim=2,\n",
    "        ansatz_depth=2,\n",
    "        optimizer='COBYLA'\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    result = model.run(maxiter=50)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    scaling_results.append({\n",
    "        'length': len(seq),\n",
    "        'n_qubits': model.encoding.n_qubits,\n",
    "        'energy': result.optimal_value,\n",
    "        'time': elapsed,\n",
    "        'iterations': result.n_iterations\n",
    "    })\n",
    "    \n",
    "    print(f\"  Qubits: {model.encoding.n_qubits}, Time: {elapsed:.2f}s\\n\")\n",
    "\n",
    "# Plot scaling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "lengths = [r['length'] for r in scaling_results]\n",
    "qubits = [r['n_qubits'] for r in scaling_results]\n",
    "times = [r['time'] for r in scaling_results]\n",
    "\n",
    "# Qubit scaling\n",
    "axes[0].plot(lengths, qubits, 'o-', linewidth=2, markersize=10)\n",
    "axes[0].set_xlabel('Protein Length', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Qubits', fontsize=12)\n",
    "axes[0].set_title('Qubit Scaling', fontweight='bold', fontsize=13)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Time scaling\n",
    "axes[1].plot(lengths, times, 's-', linewidth=2, markersize=10, color='orange')\n",
    "axes[1].set_xlabel('Protein Length', fontsize=12)\n",
    "axes[1].set_ylabel('Time (s)', fontsize=12)\n",
    "axes[1].set_title('Time-to-Solution Scaling', fontweight='bold', fontsize=13)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/vqe_scaling.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nScaling Summary:\")\n",
    "for r in scaling_results:\n",
    "    print(f\"  N={r['length']:2d}: {r['n_qubits']:2d} qubits, {r['time']:6.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we covered:\n",
    "\n",
    "1. ✅ VQE theory and Hamiltonian construction\n",
    "2. ✅ Ansatz design and circuit resources\n",
    "3. ✅ Optimizer comparison (COBYLA, SLSQP, SPSA)\n",
    "4. ✅ Parameter initialization strategies\n",
    "5. ✅ Noise analysis framework\n",
    "6. ✅ Convergence analysis\n",
    "7. ✅ Scaling behavior with protein length\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Optimizer choice** matters: COBYLA is derivative-free and robust, SLSQP faster but needs gradients\n",
    "- **Ansatz depth** trades expressivity for optimization difficulty\n",
    "- **Initialization** can significantly affect convergence speed\n",
    "- **Qubit count** scales roughly linearly with protein length (for turn encoding)\n",
    "- **Time complexity** increases with both protein size and ansatz depth\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore **03_qaoa_tutorial.ipynb** for QAOA-specific techniques\n",
    "- Try **04_benchmarking.ipynb** for systematic comparison\n",
    "\n",
    "---\n",
    "\n",
    "**Questions?** Contact: marena@cua.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
